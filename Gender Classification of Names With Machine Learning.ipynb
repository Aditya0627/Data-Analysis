{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender Classification Of Names\n",
    "### Using Machine Learning To Detect/Predict Gender of Individuals \n",
    "+ Sklearn\n",
    "+ Pandas\n",
    "+ Text Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA packages\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML Packages\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "#from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our data\n",
    "df = pd.read_csv('names_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Mary</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Anna</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Emma</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Elizabeth</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Minnie</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       name sex\n",
       "0      0       Mary   F\n",
       "1      1       Anna   F\n",
       "2      2       Emma   F\n",
       "3      3  Elizabeth   F\n",
       "4      4     Minnie   F"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "285075"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'name', 'sex'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Cleaning\n",
    "# Checking for column name consistency\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index     int64\n",
       "name     object\n",
       "sex      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index    0\n",
       "name     0\n",
       "sex      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for Missing Values\n",
    "df.isnull().isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181800"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Female Names\n",
    "df[df.sex == 'F'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103275"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Male Names\n",
    "df[df.sex == 'M'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Replacing All F and M with 0 and 1 respectively\n",
    "df_names.sex.replace({'F':0,'M':1},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_names.sex.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index     int64\n",
       "name     object\n",
       "sex       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_names.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xfeatures =df_names['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction \n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(Xfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aaban',\n",
       " 'aabha',\n",
       " 'aabid',\n",
       " 'aabriella',\n",
       " 'aada',\n",
       " 'aadam',\n",
       " 'aadan',\n",
       " 'aadarsh',\n",
       " 'aaden',\n",
       " 'aadesh',\n",
       " 'aadhav',\n",
       " 'aadhavan',\n",
       " 'aadhi',\n",
       " 'aadhira',\n",
       " 'aadhvik',\n",
       " 'aadhya',\n",
       " 'aadhyan',\n",
       " 'aadi',\n",
       " 'aadian',\n",
       " 'aadil',\n",
       " 'aadin',\n",
       " 'aadish',\n",
       " 'aadison',\n",
       " 'aadit',\n",
       " 'aadith',\n",
       " 'aadithya',\n",
       " 'aaditri',\n",
       " 'aaditya',\n",
       " 'aadiv',\n",
       " 'aadon',\n",
       " 'aadrian',\n",
       " 'aadrika',\n",
       " 'aadrit',\n",
       " 'aadvik',\n",
       " 'aadvika',\n",
       " 'aadya',\n",
       " 'aadyn',\n",
       " 'aafia',\n",
       " 'aafreen',\n",
       " 'aagam',\n",
       " 'aage',\n",
       " 'aagot',\n",
       " 'aahaan',\n",
       " 'aahan',\n",
       " 'aahana',\n",
       " 'aahil',\n",
       " 'aahir',\n",
       " 'aahliyah',\n",
       " 'aahna',\n",
       " 'aahron',\n",
       " 'aaidan',\n",
       " 'aaiden',\n",
       " 'aaidyn',\n",
       " 'aaila',\n",
       " 'aailiyah',\n",
       " 'aailyah',\n",
       " 'aaima',\n",
       " 'aaira',\n",
       " 'aairah',\n",
       " 'aaisha',\n",
       " 'aaishah',\n",
       " 'aaiyana',\n",
       " 'aaiza',\n",
       " 'aaja',\n",
       " 'aajah',\n",
       " 'aajaylah',\n",
       " 'aajon',\n",
       " 'aakanksha',\n",
       " 'aakarsh',\n",
       " 'aakash',\n",
       " 'aakeem',\n",
       " 'aakilah',\n",
       " 'aakira',\n",
       " 'aakiyah',\n",
       " 'aakriti',\n",
       " 'aala',\n",
       " 'aalaiya',\n",
       " 'aalaiyah',\n",
       " 'aalana',\n",
       " 'aalanah',\n",
       " 'aalani',\n",
       " 'aalap',\n",
       " 'aalaya',\n",
       " 'aalayah',\n",
       " 'aalayiah',\n",
       " 'aalayjah',\n",
       " 'aalayna',\n",
       " 'aalaysha',\n",
       " 'aalaysia',\n",
       " 'aalea',\n",
       " 'aaleah',\n",
       " 'aaleahya',\n",
       " 'aaleena',\n",
       " 'aaleeya',\n",
       " 'aaleeyah',\n",
       " 'aaleiah',\n",
       " 'aaleigha',\n",
       " 'aaleiyah',\n",
       " 'aalena',\n",
       " 'aalexis',\n",
       " 'aalexus',\n",
       " 'aaleya',\n",
       " 'aaleyah',\n",
       " 'aali',\n",
       " 'aalia',\n",
       " 'aaliah',\n",
       " 'aaliana',\n",
       " 'aalias',\n",
       " 'aaliayah',\n",
       " 'aaliayh',\n",
       " 'aalicia',\n",
       " 'aaliha',\n",
       " 'aalijah',\n",
       " 'aalim',\n",
       " 'aalimah',\n",
       " 'aalina',\n",
       " 'aalinah',\n",
       " 'aalisa',\n",
       " 'aalisha',\n",
       " 'aalivia',\n",
       " 'aaliya',\n",
       " 'aaliyaa',\n",
       " 'aaliyah',\n",
       " 'aaliyaha',\n",
       " 'aaliyahmarie',\n",
       " 'aaliyahrose',\n",
       " 'aaliyan',\n",
       " 'aaliyana',\n",
       " 'aaliyanna',\n",
       " 'aaliyha',\n",
       " 'aaliyiah',\n",
       " 'aalliyah',\n",
       " 'aallyah',\n",
       " 'aalok',\n",
       " 'aalon',\n",
       " 'aalya',\n",
       " 'aalyah',\n",
       " 'aalycia',\n",
       " 'aalyha',\n",
       " 'aalyia',\n",
       " 'aalyiah',\n",
       " 'aalyna',\n",
       " 'aalysia',\n",
       " 'aalyssa',\n",
       " 'aalyvia',\n",
       " 'aamanda',\n",
       " 'aamanee',\n",
       " 'aamani',\n",
       " 'aamar',\n",
       " 'aamari',\n",
       " 'aamarion',\n",
       " 'aamaya',\n",
       " 'aamber',\n",
       " 'aamena',\n",
       " 'aamer',\n",
       " 'aamia',\n",
       " 'aamil',\n",
       " 'aamilah',\n",
       " 'aamina',\n",
       " 'aaminah',\n",
       " 'aamir',\n",
       " 'aamira',\n",
       " 'aamirah',\n",
       " 'aamiya',\n",
       " 'aamiyah',\n",
       " 'aamna',\n",
       " 'aamoni',\n",
       " 'aamori',\n",
       " 'aamya',\n",
       " 'aamyah',\n",
       " 'aana',\n",
       " 'aanand',\n",
       " 'aanav',\n",
       " 'aanaya',\n",
       " 'aanchal',\n",
       " 'aania',\n",
       " 'aaniah',\n",
       " 'aanijah',\n",
       " 'aanika',\n",
       " 'aanisah',\n",
       " 'aaniya',\n",
       " 'aaniyah',\n",
       " 'aaniylah',\n",
       " 'aansh',\n",
       " 'aanshi',\n",
       " 'aanvi',\n",
       " 'aanya',\n",
       " 'aanyah',\n",
       " 'aanyla',\n",
       " 'aapri',\n",
       " 'aaqib',\n",
       " 'aaqil',\n",
       " 'aara',\n",
       " 'aarabella',\n",
       " 'aarabhi',\n",
       " 'aaradhana',\n",
       " 'aaradhy',\n",
       " 'aaradhya',\n",
       " 'aaraiz',\n",
       " 'aaralyn',\n",
       " 'aaralynn',\n",
       " 'aaran',\n",
       " 'aaraon',\n",
       " 'aaratrika',\n",
       " 'aarav',\n",
       " 'aaravi',\n",
       " 'aaraya',\n",
       " 'aaren',\n",
       " 'aareon',\n",
       " 'aareona',\n",
       " 'aari',\n",
       " 'aaria',\n",
       " 'aariah',\n",
       " 'aarian',\n",
       " 'aariana',\n",
       " 'aarianna',\n",
       " 'aarib',\n",
       " 'aaric',\n",
       " 'aarica',\n",
       " 'aarick',\n",
       " 'aarie',\n",
       " 'aariel',\n",
       " 'aarielle',\n",
       " 'aarien',\n",
       " 'aarik',\n",
       " 'aarika',\n",
       " 'aariketh',\n",
       " 'aarilyn',\n",
       " 'aarilynn',\n",
       " 'aarin',\n",
       " 'aarini',\n",
       " 'aarion',\n",
       " 'aariona',\n",
       " 'aarionna',\n",
       " 'aaris',\n",
       " 'aarish',\n",
       " 'aarit',\n",
       " 'aariv',\n",
       " 'aariya',\n",
       " 'aariyah',\n",
       " 'aariyan',\n",
       " 'aariyana',\n",
       " 'aariyanna',\n",
       " 'aariyona',\n",
       " 'aariyonna',\n",
       " 'aariz',\n",
       " 'aarjav',\n",
       " 'aarn',\n",
       " 'aarna',\n",
       " 'aarnav',\n",
       " 'aarnavi',\n",
       " 'aarne',\n",
       " 'aaro',\n",
       " 'aaroh',\n",
       " 'aarohan',\n",
       " 'aarohi',\n",
       " 'aarolyn',\n",
       " 'aaron',\n",
       " 'aarona',\n",
       " 'aaronae',\n",
       " 'aaronda',\n",
       " 'aaronette',\n",
       " 'aaronisha',\n",
       " 'aaronjacob',\n",
       " 'aaronjames',\n",
       " 'aaronjohn',\n",
       " 'aaronjoseph',\n",
       " 'aaronjosh',\n",
       " 'aaronjoshua',\n",
       " 'aaronlee',\n",
       " 'aaronmichael',\n",
       " 'aaronn',\n",
       " 'aaroosh',\n",
       " 'aarren',\n",
       " 'aarron',\n",
       " 'aarsh',\n",
       " 'aarshi',\n",
       " 'aarshiya',\n",
       " 'aarthi',\n",
       " 'aarti',\n",
       " 'aaruhi',\n",
       " 'aarush',\n",
       " 'aarushi',\n",
       " 'aarvi',\n",
       " 'aarvin',\n",
       " 'aarya',\n",
       " 'aaryah',\n",
       " 'aaryahi',\n",
       " 'aaryan',\n",
       " 'aaryana',\n",
       " 'aaryanna',\n",
       " 'aaryash',\n",
       " 'aaryav',\n",
       " 'aaryn',\n",
       " 'aaryon',\n",
       " 'aaryona',\n",
       " 'aarza',\n",
       " 'aaser',\n",
       " 'aasha',\n",
       " 'aashana',\n",
       " 'aashay',\n",
       " 'aashi',\n",
       " 'aashia',\n",
       " 'aashika',\n",
       " 'aashini',\n",
       " 'aashir',\n",
       " 'aashirya',\n",
       " 'aashish',\n",
       " 'aashita',\n",
       " 'aashiyana',\n",
       " 'aashka',\n",
       " 'aashman',\n",
       " 'aashna',\n",
       " 'aashni',\n",
       " 'aashray',\n",
       " 'aashrita',\n",
       " 'aashrith',\n",
       " 'aashritha',\n",
       " 'aashvi',\n",
       " 'aasia',\n",
       " 'aasim',\n",
       " 'aasin',\n",
       " 'aasir',\n",
       " 'aasiya',\n",
       " 'aasiyah',\n",
       " 'aason',\n",
       " 'aastha',\n",
       " 'aathan',\n",
       " 'aatif',\n",
       " 'aatish',\n",
       " 'aava',\n",
       " 'aavah',\n",
       " 'aavash',\n",
       " 'aaven',\n",
       " 'aavi',\n",
       " 'aavin',\n",
       " 'aavion',\n",
       " 'aavya',\n",
       " 'aavyan',\n",
       " 'aavyn',\n",
       " 'aaya',\n",
       " 'aayaan',\n",
       " 'aayah',\n",
       " 'aayam',\n",
       " 'aayan',\n",
       " 'aayana',\n",
       " 'aayanah',\n",
       " 'aayanna',\n",
       " 'aayansh',\n",
       " 'aayat',\n",
       " 'aaydan',\n",
       " 'aayden',\n",
       " 'aayla',\n",
       " 'aaylah',\n",
       " 'aayliah',\n",
       " 'aayra',\n",
       " 'aayu',\n",
       " 'aayush',\n",
       " 'aayusha',\n",
       " 'aayushi',\n",
       " 'aazan',\n",
       " 'aazim',\n",
       " 'aaziyah',\n",
       " 'ab',\n",
       " 'aba',\n",
       " 'abaan',\n",
       " 'abad',\n",
       " 'abagael',\n",
       " 'abagail',\n",
       " 'abagaile',\n",
       " 'abagale',\n",
       " 'abagayle',\n",
       " 'abaigael',\n",
       " 'abaigail',\n",
       " 'abaigeal',\n",
       " 'aban',\n",
       " 'abanoub',\n",
       " 'abas',\n",
       " 'abasi',\n",
       " 'abass',\n",
       " 'abayomi',\n",
       " 'abb',\n",
       " 'abba',\n",
       " 'abbaas',\n",
       " 'abbagail',\n",
       " 'abbagale',\n",
       " 'abbagayle',\n",
       " 'abbas',\n",
       " 'abbe',\n",
       " 'abbee',\n",
       " 'abbegail',\n",
       " 'abbegale',\n",
       " 'abbegayle',\n",
       " 'abbey',\n",
       " 'abbeygail',\n",
       " 'abbeygale',\n",
       " 'abbi',\n",
       " 'abbie',\n",
       " 'abbiegail',\n",
       " 'abbiegale',\n",
       " 'abbiegayle',\n",
       " 'abbigael',\n",
       " 'abbigail',\n",
       " 'abbigaile',\n",
       " 'abbigal',\n",
       " 'abbigale',\n",
       " 'abbigayl',\n",
       " 'abbigayle',\n",
       " 'abbilyn',\n",
       " 'abbot',\n",
       " 'abbott',\n",
       " 'abbra',\n",
       " 'abbriella',\n",
       " 'abbrielle',\n",
       " 'abby',\n",
       " 'abbye',\n",
       " 'abbygael',\n",
       " 'abbygail',\n",
       " 'abbygaile',\n",
       " 'abbygale',\n",
       " 'abbygayl',\n",
       " 'abbygayle',\n",
       " 'abbylynn',\n",
       " 'abcde',\n",
       " 'abd',\n",
       " 'abdala',\n",
       " 'abdalah',\n",
       " 'abdalla',\n",
       " 'abdallah',\n",
       " 'abdalrahman',\n",
       " 'abdalrhman',\n",
       " 'abdel',\n",
       " 'abdelaziz',\n",
       " 'abdelhadi',\n",
       " 'abdelkareem',\n",
       " 'abdelkarim',\n",
       " 'abdellah',\n",
       " 'abdelrahman',\n",
       " 'abdelrhman',\n",
       " 'abderrahman',\n",
       " 'abdi',\n",
       " 'abdias',\n",
       " 'abdiasis',\n",
       " 'abdiaziz',\n",
       " 'abdiel',\n",
       " 'abdifatah',\n",
       " 'abdihafid',\n",
       " 'abdihakim',\n",
       " 'abdihamid',\n",
       " 'abdikadir',\n",
       " 'abdikarim',\n",
       " 'abdikhaliq',\n",
       " 'abdilahi',\n",
       " 'abdimalik',\n",
       " 'abdinajib',\n",
       " 'abdinasir',\n",
       " 'abdiqani',\n",
       " 'abdirahim',\n",
       " 'abdirahin',\n",
       " 'abdirahman',\n",
       " 'abdirashid',\n",
       " 'abdirisaq',\n",
       " 'abdirizak',\n",
       " 'abdisalam',\n",
       " 'abdisalan',\n",
       " 'abdisamad',\n",
       " 'abdishakur',\n",
       " 'abdiwahab',\n",
       " 'abdiwali',\n",
       " 'abdo',\n",
       " 'abdon',\n",
       " 'abdou',\n",
       " 'abdoul',\n",
       " 'abdoulaye',\n",
       " 'abdoulaziz',\n",
       " 'abdoulie',\n",
       " 'abdourahman',\n",
       " 'abdourahmane',\n",
       " 'abdrahman',\n",
       " 'abdrew',\n",
       " 'abdu',\n",
       " 'abdual',\n",
       " 'abduallah',\n",
       " 'abduel',\n",
       " 'abdul',\n",
       " 'abdula',\n",
       " 'abdulah',\n",
       " 'abdulahad',\n",
       " 'abdulahi',\n",
       " 'abdulai',\n",
       " 'abdulaye',\n",
       " 'abdulazeem',\n",
       " 'abdulazeez',\n",
       " 'abdulaziz',\n",
       " 'abdulbari',\n",
       " 'abdulbasit',\n",
       " 'abdule',\n",
       " 'abdulelah',\n",
       " 'abdulhadi',\n",
       " 'abdulhakeem',\n",
       " 'abdulhakim',\n",
       " 'abdulhalim',\n",
       " 'abdulhameed',\n",
       " 'abdulhamid',\n",
       " 'abduljabbar',\n",
       " 'abduljaleel',\n",
       " 'abduljalil',\n",
       " 'abdulkadir',\n",
       " 'abdulkareem',\n",
       " 'abdulkarim',\n",
       " 'abdulkhaliq',\n",
       " 'abdull',\n",
       " 'abdulla',\n",
       " 'abdullah',\n",
       " 'abdullahi',\n",
       " 'abdullatif',\n",
       " 'abdulloh',\n",
       " 'abdulmajeed',\n",
       " 'abdulmajid',\n",
       " 'abdulmalek',\n",
       " 'abdulmalik',\n",
       " 'abdulmohsen',\n",
       " 'abdulnasir',\n",
       " 'abdulqadir',\n",
       " 'abdulraheem',\n",
       " 'abdulrahim',\n",
       " 'abdulrahman',\n",
       " 'abdulrazaq',\n",
       " 'abdulrehman',\n",
       " 'abdulrhman',\n",
       " 'abdulsalam',\n",
       " 'abdulsamad',\n",
       " 'abdulwadud',\n",
       " 'abdulwahab',\n",
       " 'abdulwahid',\n",
       " 'abdur',\n",
       " 'abdurahman',\n",
       " 'abdurahmon',\n",
       " 'abdurraheem',\n",
       " 'abdurrahim',\n",
       " 'abdurrahmaan',\n",
       " 'abdurrahman',\n",
       " 'abdurrehman',\n",
       " 'abdussamad',\n",
       " 'abe',\n",
       " 'abeal',\n",
       " 'abed',\n",
       " 'abedallah',\n",
       " 'abedalrahman',\n",
       " 'abednego',\n",
       " 'abeeha',\n",
       " 'abeer',\n",
       " 'abeera',\n",
       " 'abegail',\n",
       " 'abegale',\n",
       " 'abegayle',\n",
       " 'abel',\n",
       " 'abela',\n",
       " 'abelardo',\n",
       " 'abelina',\n",
       " 'abelino',\n",
       " 'abell',\n",
       " 'abella',\n",
       " 'abem',\n",
       " 'aben',\n",
       " 'abena',\n",
       " 'abenezer',\n",
       " 'abeni',\n",
       " 'aber',\n",
       " 'aberdeen',\n",
       " 'aberham',\n",
       " 'abernathy',\n",
       " 'abert',\n",
       " 'abery',\n",
       " 'abey',\n",
       " 'abgail',\n",
       " 'abha',\n",
       " 'abhay',\n",
       " 'abheek',\n",
       " 'abhi',\n",
       " 'abhigna',\n",
       " 'abhijay',\n",
       " 'abhijeet',\n",
       " 'abhijit',\n",
       " 'abhijot',\n",
       " 'abhik',\n",
       " 'abhilash',\n",
       " 'abhimanyu',\n",
       " 'abhinav',\n",
       " 'abhinay',\n",
       " 'abhinaya',\n",
       " 'abhiraam',\n",
       " 'abhiraj',\n",
       " 'abhiram',\n",
       " 'abhirup',\n",
       " 'abhishek',\n",
       " 'abhyuday',\n",
       " 'abi',\n",
       " 'abia',\n",
       " 'abiageal',\n",
       " 'abiah',\n",
       " 'abian',\n",
       " 'abianna',\n",
       " 'abibail',\n",
       " 'abid',\n",
       " 'abida',\n",
       " 'abidah',\n",
       " 'abidan',\n",
       " 'abie',\n",
       " 'abiegail',\n",
       " 'abiel',\n",
       " 'abiela',\n",
       " 'abiella',\n",
       " 'abiezer',\n",
       " 'abigael',\n",
       " 'abigaelle',\n",
       " 'abigahil',\n",
       " 'abigai',\n",
       " 'abigail',\n",
       " 'abigaile',\n",
       " 'abigailgrace',\n",
       " 'abigaille',\n",
       " 'abigailmarie',\n",
       " 'abigailrose',\n",
       " 'abigal',\n",
       " 'abigale',\n",
       " 'abigayil',\n",
       " 'abigayl',\n",
       " 'abigayle',\n",
       " 'abigeal',\n",
       " 'abigel',\n",
       " 'abigial',\n",
       " 'abiha',\n",
       " 'abihail',\n",
       " 'abijah',\n",
       " 'abilene',\n",
       " 'abilgail',\n",
       " 'abilio',\n",
       " 'abilyn',\n",
       " 'abilynn',\n",
       " 'abimael',\n",
       " 'abimbola',\n",
       " 'abimelec',\n",
       " 'abin',\n",
       " 'abinadab',\n",
       " 'abinadi',\n",
       " 'abinav',\n",
       " 'abinaya',\n",
       " 'abiodun',\n",
       " 'abiola',\n",
       " 'abiona',\n",
       " 'abir',\n",
       " 'abira',\n",
       " 'abiram',\n",
       " 'abirami',\n",
       " 'abisag',\n",
       " 'abisai',\n",
       " 'abish',\n",
       " 'abisha',\n",
       " 'abishai',\n",
       " 'abishek',\n",
       " 'abisola',\n",
       " 'abiud',\n",
       " 'abiyah',\n",
       " 'abla',\n",
       " 'able',\n",
       " 'abnel',\n",
       " 'abner',\n",
       " 'abney',\n",
       " 'abony',\n",
       " 'abou',\n",
       " 'aboubacar',\n",
       " 'aboubakar',\n",
       " 'abra',\n",
       " 'abraam',\n",
       " 'abraar',\n",
       " 'abrah',\n",
       " 'abraham',\n",
       " 'abrahan',\n",
       " 'abraheem',\n",
       " 'abrahem',\n",
       " 'abrahim',\n",
       " 'abrahm',\n",
       " 'abram',\n",
       " 'abran',\n",
       " 'abranda',\n",
       " 'abrar',\n",
       " 'abraxas',\n",
       " 'abrea',\n",
       " 'abreana',\n",
       " 'abreanna',\n",
       " 'abree',\n",
       " 'abreia',\n",
       " 'abren',\n",
       " 'abreona',\n",
       " 'abreonna',\n",
       " 'abrey',\n",
       " 'abreya',\n",
       " 'abrham',\n",
       " 'abri',\n",
       " 'abria',\n",
       " 'abriah',\n",
       " 'abrial',\n",
       " 'abriam',\n",
       " 'abrian',\n",
       " 'abriana',\n",
       " 'abrianna',\n",
       " 'abriannah',\n",
       " 'abrianne',\n",
       " 'abrie',\n",
       " 'abriel',\n",
       " 'abriela',\n",
       " 'abriele',\n",
       " 'abriella',\n",
       " 'abrielle',\n",
       " 'abrien',\n",
       " 'abrienne',\n",
       " 'abrigail',\n",
       " 'abrihet',\n",
       " 'abril',\n",
       " 'abrille',\n",
       " 'abrina',\n",
       " 'abrion',\n",
       " 'abriona',\n",
       " 'abrionna',\n",
       " 'abrish',\n",
       " 'abriya',\n",
       " 'abriyah',\n",
       " 'abriyana',\n",
       " 'abrom',\n",
       " 'abron',\n",
       " 'abrum',\n",
       " 'abry',\n",
       " 'abryana',\n",
       " 'abryanna',\n",
       " 'abryella',\n",
       " 'abryelle',\n",
       " 'abryl',\n",
       " 'absalat',\n",
       " 'absalom',\n",
       " 'absalon',\n",
       " 'abshir',\n",
       " 'absidy',\n",
       " 'abtin',\n",
       " 'abu',\n",
       " 'abubacar',\n",
       " 'abubacarr',\n",
       " 'abubakar',\n",
       " 'abubakarr',\n",
       " 'abubakary',\n",
       " 'abubaker',\n",
       " 'abubakr',\n",
       " 'abuk',\n",
       " 'abukar',\n",
       " 'abundio',\n",
       " 'aby',\n",
       " 'abyade',\n",
       " 'abyan',\n",
       " 'abygael',\n",
       " 'abygail',\n",
       " 'abygaile',\n",
       " 'abygale',\n",
       " 'abygayle',\n",
       " 'abyssinia',\n",
       " 'ac',\n",
       " 'acacia',\n",
       " 'acacius',\n",
       " 'acadia',\n",
       " 'acamas',\n",
       " 'acari',\n",
       " 'acasia',\n",
       " 'accacia',\n",
       " 'accalia',\n",
       " 'access',\n",
       " 'accie',\n",
       " 'accursio',\n",
       " 'ace',\n",
       " 'acea',\n",
       " 'acein',\n",
       " 'acel',\n",
       " 'acelin',\n",
       " 'acelino',\n",
       " 'acelyn',\n",
       " 'acelynn',\n",
       " 'acen',\n",
       " 'acencion',\n",
       " 'aceon',\n",
       " 'acer',\n",
       " 'aceson',\n",
       " 'acesyn',\n",
       " 'aceton',\n",
       " 'acey',\n",
       " 'aceyn',\n",
       " 'achai',\n",
       " 'achaia',\n",
       " 'achan',\n",
       " 'achante',\n",
       " 'achanti',\n",
       " 'achary',\n",
       " 'achazia',\n",
       " 'achel',\n",
       " 'acheron',\n",
       " 'achille',\n",
       " 'achilles',\n",
       " 'achilleus',\n",
       " 'achillies',\n",
       " 'achintya',\n",
       " 'achol',\n",
       " 'achraf',\n",
       " 'achsa',\n",
       " 'achsah',\n",
       " 'achyut',\n",
       " 'achyuth',\n",
       " 'acia',\n",
       " 'aciano',\n",
       " 'acie',\n",
       " 'aciel',\n",
       " 'acil',\n",
       " 'acire',\n",
       " 'ackeem',\n",
       " 'ackley',\n",
       " 'acob',\n",
       " 'acquanetta',\n",
       " 'acquanette',\n",
       " 'acsa',\n",
       " 'acura',\n",
       " 'acxel',\n",
       " 'acy',\n",
       " 'ad',\n",
       " 'ada',\n",
       " 'adabel',\n",
       " 'adabella',\n",
       " 'adabelle',\n",
       " 'adacia',\n",
       " 'adae',\n",
       " 'adael',\n",
       " 'adaelyn',\n",
       " 'adaeze',\n",
       " 'adagio',\n",
       " 'adah',\n",
       " 'adahir',\n",
       " 'adahli',\n",
       " 'adahlia',\n",
       " 'adahy',\n",
       " 'adai',\n",
       " 'adaia',\n",
       " 'adaiah',\n",
       " 'adaija',\n",
       " 'adaijah',\n",
       " 'adailyn',\n",
       " 'adain',\n",
       " 'adair',\n",
       " 'adaira',\n",
       " 'adaire',\n",
       " 'adairis',\n",
       " 'adaisha',\n",
       " 'adaisia',\n",
       " 'adaja',\n",
       " 'adajah',\n",
       " 'adaku',\n",
       " 'adal',\n",
       " 'adala',\n",
       " 'adalade',\n",
       " 'adalae',\n",
       " 'adalai',\n",
       " 'adalaide',\n",
       " 'adalay',\n",
       " 'adalaya',\n",
       " 'adalayde',\n",
       " 'adalbert',\n",
       " 'adalberto',\n",
       " 'adale',\n",
       " 'adalea',\n",
       " 'adaleah',\n",
       " 'adalee',\n",
       " 'adaleen',\n",
       " 'adaleena',\n",
       " 'adalei',\n",
       " 'adaleia',\n",
       " 'adaleigh',\n",
       " 'adaleine',\n",
       " 'adalen',\n",
       " 'adalena',\n",
       " 'adalene',\n",
       " 'adaley',\n",
       " 'adaleya',\n",
       " 'adaleyza',\n",
       " 'adalhi',\n",
       " 'adali',\n",
       " 'adalia',\n",
       " 'adaliah',\n",
       " 'adalicia',\n",
       " 'adalid',\n",
       " 'adalida',\n",
       " 'adalie',\n",
       " 'adaliene',\n",
       " 'adalin',\n",
       " 'adalina',\n",
       " 'adalind',\n",
       " 'adalinda',\n",
       " 'adaline',\n",
       " 'adalinn',\n",
       " 'adalinne',\n",
       " 'adalis',\n",
       " 'adalisa',\n",
       " 'adalise',\n",
       " 'adalisse',\n",
       " 'adalius',\n",
       " 'adaliyah',\n",
       " 'adaliz',\n",
       " 'adalize',\n",
       " 'adallyn',\n",
       " 'adaly',\n",
       " 'adalya',\n",
       " 'adalye',\n",
       " 'adalyn',\n",
       " 'adalyna',\n",
       " 'adalynd',\n",
       " 'adalyne',\n",
       " 'adalynn',\n",
       " 'adalynne',\n",
       " 'adalys',\n",
       " 'adalyse',\n",
       " 'adam',\n",
       " 'adama',\n",
       " 'adamae',\n",
       " 'adamari',\n",
       " 'adamarie',\n",
       " 'adamaris',\n",
       " 'adamariz',\n",
       " 'adamary',\n",
       " 'adamarys',\n",
       " 'adamina',\n",
       " 'adamm',\n",
       " 'adamma',\n",
       " 'adammichael',\n",
       " 'adamo',\n",
       " 'adams',\n",
       " 'adan',\n",
       " 'adana',\n",
       " 'adaneli',\n",
       " 'adanelly',\n",
       " 'adanely',\n",
       " 'adanna',\n",
       " 'adannaya',\n",
       " 'adante',\n",
       " 'adanya',\n",
       " 'adaobi',\n",
       " 'adaora',\n",
       " 'adar',\n",
       " 'adara',\n",
       " 'adarah',\n",
       " 'adari',\n",
       " 'adaria',\n",
       " 'adarian',\n",
       " 'adarien',\n",
       " 'adarion',\n",
       " 'adarious',\n",
       " 'adarius',\n",
       " 'adarrius',\n",
       " 'adarryl',\n",
       " 'adarryll',\n",
       " 'adarsh',\n",
       " 'adaryl',\n",
       " 'adaryll',\n",
       " 'adasha',\n",
       " 'adashia',\n",
       " 'adasia',\n",
       " 'adason',\n",
       " 'adassa',\n",
       " 'adasyn',\n",
       " 'adaugo',\n",
       " 'adaure',\n",
       " 'adavia',\n",
       " 'adavion',\n",
       " 'adaya',\n",
       " 'adayah',\n",
       " 'adayla',\n",
       " 'adaysha',\n",
       " 'adayshia',\n",
       " 'adaysia',\n",
       " 'adbeel',\n",
       " 'adbiel',\n",
       " 'add',\n",
       " 'adda',\n",
       " 'addah',\n",
       " 'addai',\n",
       " 'addalee',\n",
       " 'addaleigh',\n",
       " 'addaley',\n",
       " 'addalie',\n",
       " 'addalin',\n",
       " 'addalina',\n",
       " 'addaline',\n",
       " 'addalyn',\n",
       " 'addalyne',\n",
       " 'addalynn',\n",
       " 'addalynne',\n",
       " 'addam',\n",
       " 'addan',\n",
       " ...]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features \n",
    "X\n",
    "# Labels\n",
    "y = df_names.sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6398163206734908"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes Classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train,y_train)\n",
    "clf.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model 63.98163206734908 %\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of our Model\n",
    "print(\"Accuracy of Model\",clf.score(X_test,y_test)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model 100.0 %\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of our Model\n",
    "print(\"Accuracy of Model\",clf.score(X_train,y_train)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample1 Prediction\n",
    "sample_name = [\"Mary\"]\n",
    "vect = cv.transform(sample_name).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Female is 0, Male is 1\n",
    "clf.predict(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample2 Prediction\n",
    "sample_name1 = [\"Mark\"]\n",
    "vect1 = cv.transform(sample_name1).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(vect1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample3 Prediction of Russian Names\n",
    "sample_name2 = [\"Natasha\"]\n",
    "vect2 = cv.transform(sample_name2).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(vect2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample3 Prediction of Random Names\n",
    "sample_name3 = [\"Nefertiti\",\"Nasha\",\"Ama\",\"Ayo\",\"Xhavier\",\"Ovetta\",\"Tathiana\",\"Xia\",\"Joseph\",\"Xianliang\"]\n",
    "vect3 = cv.transform(sample_name3).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(vect3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to do it\n",
    "def genderpredictor(a):\n",
    "    test_name = [a]\n",
    "    vector = cv.transform(test_name).toarray()\n",
    "    if clf.predict(vector) == 0:\n",
    "        print(\"Female\")\n",
    "    else:\n",
    "        print(\"Male\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Female\n"
     ]
    }
   ],
   "source": [
    "genderpredictor(\"Martha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Female\n",
      "None\n",
      "Male\n",
      "None\n",
      "Female\n",
      "None\n",
      "Female\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "namelist = [\"Yaa\",\"Yaw\",\"Femi\",\"Masha\"]\n",
    "for i in namelist:\n",
    "    print(genderpredictor(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a custom function for feature analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By Analogy most female names ends in 'A' or 'E' or has the sound of 'A'\n",
    "def features(name):\n",
    "    name = name.lower()\n",
    "    return {\n",
    "        'first-letter': name[0], # First letter\n",
    "        'first2-letters': name[0:2], # First 2 letters\n",
    "        'first3-letters': name[0:3], # First 3 letters\n",
    "        'last-letter': name[-1],\n",
    "        'last2-letters': name[-2:],\n",
    "        'last3-letters': name[-3:],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'first-letter': 'a', 'first2-letters': 'an', 'first3-letters': 'ann', 'last-letter': 'a', 'last2-letters': 'na', 'last3-letters': 'nna'}\n",
      " {'first-letter': 'h', 'first2-letters': 'ha', 'first3-letters': 'han', 'last-letter': 'h', 'last2-letters': 'ah', 'last3-letters': 'nah'}\n",
      " {'first-letter': 'p', 'first2-letters': 'pe', 'first3-letters': 'pet', 'last-letter': 'r', 'last2-letters': 'er', 'last3-letters': 'ter'}\n",
      " {'first-letter': 'j', 'first2-letters': 'jo', 'first3-letters': 'joh', 'last-letter': 'n', 'last2-letters': 'hn', 'last3-letters': 'ohn'}\n",
      " {'first-letter': 'v', 'first2-letters': 'vl', 'first3-letters': 'vla', 'last-letter': 'r', 'last2-letters': 'ir', 'last3-letters': 'mir'}\n",
      " {'first-letter': 'm', 'first2-letters': 'mo', 'first3-letters': 'moh', 'last-letter': 'd', 'last2-letters': 'ed', 'last3-letters': 'med'}]\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the features function\n",
    "features = np.vectorize(features)\n",
    "print(features([\"Anna\", \"Hannah\", \"Peter\",\"John\",\"Vladmir\",\"Mohammed\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the features for the dataset\n",
    "df_X = features(df_names['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = df_names['sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1.0\n",
      "  (0, 3)\t1.0\n",
      "  (0, 5)\t1.0\n",
      "  (0, 7)\t1.0\n",
      "  (0, 9)\t1.0\n",
      "  (0, 10)\t1.0\n",
      "  (1, 0)\t1.0\n",
      "  (1, 2)\t1.0\n",
      "  (1, 4)\t1.0\n",
      "  (1, 6)\t1.0\n",
      "  (1, 8)\t1.0\n",
      "  (1, 11)\t1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    " \n",
    "corpus = features([\"Mike\", \"Julia\"])\n",
    "dv = DictVectorizer()\n",
    "dv.fit(corpus)\n",
    "transformed = dv.transform(corpus)\n",
    "print(transformed)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['first-letter=j',\n",
       " 'first-letter=m',\n",
       " 'first2-letters=ju',\n",
       " 'first2-letters=mi',\n",
       " 'first3-letters=jul',\n",
       " 'first3-letters=mik',\n",
       " 'last-letter=a',\n",
       " 'last-letter=e',\n",
       " 'last2-letters=ia',\n",
       " 'last2-letters=ke',\n",
       " 'last3-letters=ike',\n",
       " 'last3-letters=lia']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "dfX_train, dfX_test, dfy_train, dfy_test = train_test_split(df_X, df_y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'first-letter': 'e', 'first2-letters': 'el', 'first3-letters': 'ele', 'last-letter': 'a', 'last2-letters': 'ia', 'last3-letters': 'nia'},\n",
       "       {'first-letter': 'a', 'first2-letters': 'ad', 'first3-letters': 'adi', 'last-letter': 'l', 'last2-letters': 'il', 'last3-letters': 'dil'},\n",
       "       {'first-letter': 'k', 'first2-letters': 'ka', 'first3-letters': 'kad', 'last-letter': 'e', 'last2-letters': 'ze', 'last3-letters': 'nze'},\n",
       "       ...,\n",
       "       {'first-letter': 'j', 'first2-letters': 'ja', 'first3-letters': 'jaz', 'last-letter': 'y', 'last2-letters': 'ly', 'last3-letters': 'zly'},\n",
       "       {'first-letter': 'e', 'first2-letters': 'el', 'first3-letters': 'elv', 'last-letter': 'a', 'last2-letters': 'na', 'last3-letters': 'ina'},\n",
       "       {'first-letter': 'l', 'first2-letters': 'le', 'first3-letters': 'led', 'last-letter': 'r', 'last2-letters': 'er', 'last3-letters': 'ger'}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfX_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<63666x8194 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 381996 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dv = DictVectorizer()\n",
    "dv.fit_transform(dfX_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model building Using DecisionTree\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    " \n",
    "dclf = DecisionTreeClassifier()\n",
    "my_xfeatures =dv.transform(dfX_train)\n",
    "dclf.fit(my_xfeatures, dfy_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build Features and Transform them\n",
    "sample_name_eg = [\"Alex\"]\n",
    "transform_dv =dv.transform(features(sample_name_eg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect3 = transform_dv.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting Gender of Name\n",
    "# Male is 1,female = 0\n",
    "dclf.predict(vect3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male\n"
     ]
    }
   ],
   "source": [
    "if dclf.predict(vect3) == 0:\n",
    "    print(\"Female\")\n",
    "else:\n",
    "    print(\"Male\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Female\n"
     ]
    }
   ],
   "source": [
    "# Second Prediction With Nigerian Name\n",
    "name_eg1 = [\"Chioma\"]\n",
    "transform_dv =dv.transform(features(name_eg1))\n",
    "vect4 = transform_dv.toarray()\n",
    "if dclf.predict(vect4) == 0:\n",
    "    print(\"Female\")\n",
    "else:\n",
    "    print(\"Male\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to do it\n",
    "def genderpredictor1(a):\n",
    "    test_name1 = [a]\n",
    "    transform_dv =dv.transform(features(test_name1))\n",
    "    vector = transform_dv.toarray()\n",
    "    if dclf.predict(vector) == 0:\n",
    "        print(\"Female\")\n",
    "    else:\n",
    "        print(\"Male\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_name_list = [\"Alex\",\"Alice\",\"Chioma\",\"Vitalic\",\"Clairese\",\"Chan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male\n",
      "None\n",
      "Female\n",
      "None\n",
      "Female\n",
      "None\n",
      "Male\n",
      "None\n",
      "Female\n",
      "None\n",
      "Male\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for n in random_name_list:\n",
    "    print(genderpredictor1(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9888951716771903\n"
     ]
    }
   ],
   "source": [
    "## Accuracy of Models Decision Tree Classifier Works better than Naive Bayes\n",
    "# Accuracy on training set\n",
    "print(dclf.score(dv.transform(dfX_train), dfy_train)) \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8670238209126566\n"
     ]
    }
   ],
   "source": [
    "# Accuracy on test set\n",
    "print(dclf.score(dv.transform(dfX_test), dfy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf = pd.read_csv('new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review_author</th>\n",
       "      <th>review_Country</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Rob</td>\n",
       "      <td>GB</td>\n",
       "      <td>Attrocious company that made mistake after mis...</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>S. L</td>\n",
       "      <td>GB</td>\n",
       "      <td>Missing box</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Imran Alvi</td>\n",
       "      <td>GB</td>\n",
       "      <td>Very bad service</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Jonatan Karlsson</td>\n",
       "      <td>GB</td>\n",
       "      <td>Complete Admin Chaos</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Francesco Merletti</td>\n",
       "      <td>GB</td>\n",
       "      <td>Boxes returned smashed, ripped and smelly</td>\n",
       "      <td>2</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>265</td>\n",
       "      <td>J</td>\n",
       "      <td>GB</td>\n",
       "      <td>Poor service.</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>266</td>\n",
       "      <td>Maria</td>\n",
       "      <td>GB</td>\n",
       "      <td>Extremely bad service</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>267</td>\n",
       "      <td>Thelma H.</td>\n",
       "      <td>GB</td>\n",
       "      <td>Labels Labels LABELS!</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>268</td>\n",
       "      <td>Panos</td>\n",
       "      <td>GB</td>\n",
       "      <td>Not bad</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>269</td>\n",
       "      <td>erika</td>\n",
       "      <td>GB</td>\n",
       "      <td>Dreadful experience</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0       review_author review_Country  \\\n",
       "0             0                 Rob             GB   \n",
       "1             1                S. L             GB   \n",
       "2             2          Imran Alvi             GB   \n",
       "3             3    Jonatan Karlsson             GB   \n",
       "4             4  Francesco Merletti             GB   \n",
       "..          ...                 ...            ...   \n",
       "265         265                   J             GB   \n",
       "266         266               Maria             GB   \n",
       "267         267           Thelma H.             GB   \n",
       "268         268               Panos             GB   \n",
       "269         269               erika             GB   \n",
       "\n",
       "                                       review_headline  review_rating   Gender  \n",
       "0    Attrocious company that made mistake after mis...              1     male  \n",
       "1                                          Missing box              1  unknown  \n",
       "2                                     Very bad service              1  unknown  \n",
       "3                                 Complete Admin Chaos              1  unknown  \n",
       "4            Boxes returned smashed, ripped and smelly              2  unknown  \n",
       "..                                                 ...            ...      ...  \n",
       "265                                      Poor service.              1  unknown  \n",
       "266                              Extremely bad service              1   female  \n",
       "267                              Labels Labels LABELS!              1  unknown  \n",
       "268                                            Not bad              3     male  \n",
       "269                                Dreadful experience              1  unknown  \n",
       "\n",
       "[270 rows x 6 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Female\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Female\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Female\n"
     ]
    }
   ],
   "source": [
    "list1 = dataf['review_author']\n",
    "list2 = []\n",
    "for i in list1:\n",
    "    list2.append(genderpredictor1(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisiontreModel = open(\"decisiontreemodel.pkl\",\"wb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function BufferedWriter.close>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decisiontreModel.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternative to Model Saving\n",
    "import pickle\n",
    "dctreeModel = open(\"namesdetectormodel.pkl\",\"wb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(dclf,dctreeModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dctreeModel.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save Multinomial NB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "NaiveBayesModel = open(\"naivebayesgendermodel.pkl\",\"wb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "NaiveBayesModel.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#listt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#listt = [dataf['review_author']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import requests, json \\n\\ndef getGenders(names):\\n\\turl = \"\"\\n\\tcnt = 0\\n\\t#if not isinstance(names,list):\\n\\t\\t#names = [names,]\\n\\t\\n\\tfor name in names:\\n\\t\\tif url == \"\":\\n\\t\\t\\turl = \"name[0]=\" + name\\n\\t\\telse:\\n\\t\\t\\tcnt += 1\\n\\t\\t\\turl = url + \"&name[\" + str(cnt) + \"]=\" + name\\n\\t\\t\\n\\n\\treq = requests.get(\"https://api.genderize.io?\" + url)\\n\\tresults = json.loads(req.text)\\n\\t\\n\\tretrn = []\\n\\tfor result in results:\\n\\t\\tif result[\"gender\"] is not None:\\n\\t\\t\\tretrn.append((result[\"gender\"], result[\"probability\"], result[\"count\"]))\\n\\t\\telse:\\n\\t\\t\\tretrn.append((u\\'None\\',u\\'0.0\\',0.0))\\n\\treturn retrn\\n\\nif __name__ == \\'__main__\\':\\n\\tprint(getGenders(listt))'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import requests, json \n",
    "\n",
    "def getGenders(names):\n",
    "\turl = \"\"\n",
    "\tcnt = 0\n",
    "\t#if not isinstance(names,list):\n",
    "\t\t#names = [names,]\n",
    "\t\n",
    "\tfor name in names:\n",
    "\t\tif url == \"\":\n",
    "\t\t\turl = \"name[0]=\" + name\n",
    "\t\telse:\n",
    "\t\t\tcnt += 1\n",
    "\t\t\turl = url + \"&name[\" + str(cnt) + \"]=\" + name\n",
    "\t\t\n",
    "\n",
    "\treq = requests.get(\"https://api.genderize.io?\" + url)\n",
    "\tresults = json.loads(req.text)\n",
    "\t\n",
    "\tretrn = []\n",
    "\tfor result in results:\n",
    "\t\tif result[\"gender\"] is not None:\n",
    "\t\t\tretrn.append((result[\"gender\"], result[\"probability\"], result[\"count\"]))\n",
    "\t\telse:\n",
    "\t\t\tretrn.append((u'None',u'0.0',0.0))\n",
    "\treturn retrn\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tprint(getGenders(listt))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg = pd.read_csv('aadi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfg = dfg.drop(['Unnamed: 0', 'review_author'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d = pd.concat([dfg, yo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yo['review_date'] = dfg['review_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yo.to_csv('rev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfg = dfg.iloc[0:1072, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review_author</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Chris</td>\n",
       "      <td>We have our pax wardrobes from July</td>\n",
       "      <td>We have our pax wardrobes from July, no mesh b...</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-11-04T21:27:43.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Shaf</td>\n",
       "      <td>System states my order has been picked</td>\n",
       "      <td>System states my order has been picked up from...</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-11-04T10:56:05.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>andrew williams</td>\n",
       "      <td>Never get anything on line and expect a</td>\n",
       "      <td>Never get anything on line and expect a delive...</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-11-04T09:51:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Rachel Bosshard</td>\n",
       "      <td>IKEA delivery</td>\n",
       "      <td>I know many of you might be IKEA fans so I tho...</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-11-03T15:51:12.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Leanne Batt</td>\n",
       "      <td>The quality of the customer service is</td>\n",
       "      <td>The quality of the customer service is as low ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-11-03T13:40:28.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5075</th>\n",
       "      <td>5075</td>\n",
       "      <td>Yun-Jui Tseng</td>\n",
       "      <td>Requested a cancellation due to several</td>\n",
       "      <td>Requested a cancellation due to several delays...</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-10-31T07:38:30.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5076</th>\n",
       "      <td>5076</td>\n",
       "      <td>X.Li</td>\n",
       "      <td>good customer service</td>\n",
       "      <td>good customer service</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-10-30T21:38:40.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5077</th>\n",
       "      <td>5077</td>\n",
       "      <td>shisong jiang</td>\n",
       "      <td>Worst customer services.</td>\n",
       "      <td>Worst customer services.Ordered a set of wardr...</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-10-30T13:32:14.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5078</th>\n",
       "      <td>5078</td>\n",
       "      <td>Theresa</td>\n",
       "      <td>Excellent customer service from Kai</td>\n",
       "      <td>Excellent customer service from Kai, he was so...</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-10-30T09:08:35.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5079</th>\n",
       "      <td>5079</td>\n",
       "      <td>Lukas Wykocki</td>\n",
       "      <td>The worst experiance ever with Ikea</td>\n",
       "      <td>The worst experiance ever with Ikea !!!! They ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-10-29T18:52:28.000Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5080 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0    review_author                           review_headline  \\\n",
       "0              0            Chris       We have our pax wardrobes from July   \n",
       "1              1             Shaf   System states my order has been picked   \n",
       "2              2  andrew williams  Never get anything on line and expect a   \n",
       "3              3  Rachel Bosshard                             IKEA delivery   \n",
       "4              4      Leanne Batt   The quality of the customer service is   \n",
       "...          ...              ...                                       ...   \n",
       "5075        5075    Yun-Jui Tseng  Requested a cancellation due to several   \n",
       "5076        5076             X.Li                     good customer service   \n",
       "5077        5077    shisong jiang                  Worst customer services.   \n",
       "5078        5078          Theresa       Excellent customer service from Kai   \n",
       "5079        5079    Lukas Wykocki      The worst experiance ever with Ikea   \n",
       "\n",
       "                                            review_text  review_rating  \\\n",
       "0     We have our pax wardrobes from July, no mesh b...              1   \n",
       "1     System states my order has been picked up from...              1   \n",
       "2     Never get anything on line and expect a delive...              1   \n",
       "3     I know many of you might be IKEA fans so I tho...              1   \n",
       "4     The quality of the customer service is as low ...              1   \n",
       "...                                                 ...            ...   \n",
       "5075  Requested a cancellation due to several delays...              1   \n",
       "5076                              good customer service              5   \n",
       "5077  Worst customer services.Ordered a set of wardr...              1   \n",
       "5078  Excellent customer service from Kai, he was so...              5   \n",
       "5079  The worst experiance ever with Ikea !!!! They ...              1   \n",
       "\n",
       "                   review_date  \n",
       "0     2021-11-04T21:27:43.000Z  \n",
       "1     2021-11-04T10:56:05.000Z  \n",
       "2     2021-11-04T09:51:00.000Z  \n",
       "3     2021-11-03T15:51:12.000Z  \n",
       "4     2021-11-03T13:40:28.000Z  \n",
       "...                        ...  \n",
       "5075  2021-10-31T07:38:30.000Z  \n",
       "5076  2021-10-30T21:38:40.000Z  \n",
       "5077  2021-10-30T13:32:14.000Z  \n",
       "5078  2021-10-30T09:08:35.000Z  \n",
       "5079  2021-10-29T18:52:28.000Z  \n",
       "\n",
       "[5080 rows x 6 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'review_author', 'review_headline', 'review_text',\n",
       "       'review_rating', 'review_date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfg.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'lista = dfg['review_author']\\nl2  = []\\nfor i in lista:\\n    l2.append(genderpredictor1(i))\""
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''''lista = dfg['review_author']\n",
    "l2  = []\n",
    "for i in lista:\n",
    "    l2.append(genderpredictor1(i))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfg = dfg.drop(['Unnamed: 0', 'review_headline', 'review_text',\n",
    "   #    'review_rating', 'review_date'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(dfg['review_author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Name = dfg['review_author'].tolist()\\nName\\nyup = []\\nfor i in Name:\\n    yup.append(genderpredictor1(i))\""
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Name = dfg['review_author'].tolist()\n",
    "Name\n",
    "yup = []\n",
    "for i in Name:\n",
    "    yup.append(genderpredictor1(i))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in n2:\n",
    " #   print(n2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#li = lista[0:1072]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"dic = {\\n    'names': li,\\n    'gender': ll\\n}\""
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''dic = {\n",
    "    'names': li,\n",
    "    'gender': ll\n",
    "}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yo = pd.DataFrame(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yo.to_csv('names_gen.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p1 = pd.read_csv('Csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lmm = [p1['Name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(lmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lp  = []\\nfor i in lo:\\n    lp.append(genderpredictor1(i))'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''lp  = []\n",
    "for i in lo:\n",
    "    lp.append(genderpredictor1(i))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = pd.read_csv('Csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = csv['Name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rob',\n",
       " 'Sabine L',\n",
       " 'Imran Alvi',\n",
       " 'Jonatan Karlsson',\n",
       " 'Ewa',\n",
       " 'ekin rnek',\n",
       " 'Martina Nedkova',\n",
       " 'aseel sultan',\n",
       " 'Sylvie',\n",
       " 'Alexandra Badut',\n",
       " 'Lawsuit',\n",
       " 'Linus',\n",
       " 'Marilyn Ohemaa',\n",
       " 'Rafeeda Abedin',\n",
       " 'Maria Vittoria',\n",
       " 'AP',\n",
       " 'Nathalie Clark',\n",
       " 'Clau Ramos',\n",
       " 'Laura Biezup',\n",
       " 'Scarlett,',\n",
       " 'Tabitha Mullock',\n",
       " 'Christopher Onderstall',\n",
       " 'Ann-Michelle Mull',\n",
       " 'Alex G',\n",
       " 'Julia',\n",
       " 'Shen May Khoo',\n",
       " 'Joana',\n",
       " 'jorge kronfle',\n",
       " 'Zaya G',\n",
       " 'Claudia Hon',\n",
       " 'Jonty',\n",
       " 'Claudia Hon',\n",
       " 'Julie',\n",
       " '\\xa0Hyunhoi',\n",
       " 'Afsana Mahtani',\n",
       " 'Antonella',\n",
       " '\\xa0Hyunhoi,',\n",
       " 'Manu Moreau',\n",
       " 'Khalad Al-Muhaysh',\n",
       " 'Selina Abdul Kareem',\n",
       " 'Srika N.',\n",
       " 'Fanni Szabo',\n",
       " 'Aiwen Chua',\n",
       " 'Katrina So',\n",
       " 'Sang Hun Kim',\n",
       " 'Rena Abidova',\n",
       " 'G O-I',\n",
       " 'Kittipit Viseshsin',\n",
       " 'Iustina Chirila',\n",
       " 'Yara Ha',\n",
       " 'Raluca Baicu',\n",
       " 'Burcu',\n",
       " 'Yana',\n",
       " 'Yana Pencheva',\n",
       " 'Srika N.',\n",
       " 'Jess',\n",
       " 'Michal',\n",
       " 'Max Hombach',\n",
       " 'Luca',\n",
       " 'Saksham',\n",
       " 'Penghui Shi',\n",
       " 'Panagiotis Gr',\n",
       " 'Joanna Rie',\n",
       " 'Odette Duerden',\n",
       " 'anda oglakci',\n",
       " 'Rhiannon',\n",
       " ' ',\n",
       " 'Natasha',\n",
       " 'Patricia Eliana Gheorghe',\n",
       " 'Julita Stefaniak',\n",
       " 'Ian Wong',\n",
       " 'JSJ GANG',\n",
       " 'Musomum',\n",
       " 'Baldpenguin',\n",
       " 'Wink',\n",
       " 'Matthew',\n",
       " 'Petra Dietz',\n",
       " 'Trisyia',\n",
       " 'ediblesweater',\n",
       " 'Diane',\n",
       " 'Mary Ana',\n",
       " 'Jon',\n",
       " 'Chloe',\n",
       " 'Broke uni stduent',\n",
       " 'Sebastiano Pignato',\n",
       " 'Jehquisha',\n",
       " 'Keana',\n",
       " 'Liv',\n",
       " 'mike',\n",
       " 'mike',\n",
       " 'NL',\n",
       " 'Yagmur',\n",
       " 'Sam',\n",
       " 'Saharat Anuwatmatee',\n",
       " 'Hayley',\n",
       " 'Victoria Recean',\n",
       " 'kp',\n",
       " 'James',\n",
       " 'Fay',\n",
       " 'Nneoma',\n",
       " 'Mizza',\n",
       " 'Karen',\n",
       " 'c mason',\n",
       " 'Aisha',\n",
       " 'Arnau',\n",
       " 'Flo',\n",
       " 'Rachael',\n",
       " 'Tebogo Bembe',\n",
       " 'Yitong Wang',\n",
       " 'Rebecca',\n",
       " 'Anonymous',\n",
       " 'wong hoikwan',\n",
       " 'Vladimir Sagalevich',\n",
       " 'Konstantina Sotiriou',\n",
       " 'Kay Wong',\n",
       " 'tejiri ishaka',\n",
       " 'Mizza',\n",
       " '',\n",
       " 'Mir',\n",
       " 'Victoria E Nwokolo',\n",
       " 'Marta',\n",
       " 'Jade Johnson',\n",
       " 'Ariel Chen',\n",
       " 'MB',\n",
       " 'Yasmine Aminanda',\n",
       " 'Daniel Ooi',\n",
       " 'Lenita LuxV',\n",
       " 'Zen Dhammatorn',\n",
       " 'Mizza',\n",
       " 'Samuel Mensah',\n",
       " 'leigh',\n",
       " 'Xin Di Kwong',\n",
       " 'Daniela Simes',\n",
       " 'Ariane Strike',\n",
       " '*',\n",
       " 'Sophia C',\n",
       " 'Rahil Gandhi',\n",
       " 'Charlotte Bowerman',\n",
       " 'agnes roze',\n",
       " 'Rahil Gandhi',\n",
       " 'Yuou Zhao',\n",
       " 'Charlotte',\n",
       " 'daniel',\n",
       " 'yasmin timol',\n",
       " 'Will Marchant',\n",
       " 'Maggie Talty-Sanghera',\n",
       " 'Constanza Mondragon',\n",
       " 'S Kelly',\n",
       " 'Ronin',\n",
       " 'Becky Says',\n",
       " 'ANASTASIA',\n",
       " 'Damien Gal',\n",
       " 'Oliver',\n",
       " 'MD',\n",
       " 'Wei Vern Kok',\n",
       " 'Sherice',\n",
       " 'Charles',\n",
       " 'Frank Li',\n",
       " 'Tamara Garcia Pereira',\n",
       " 'Godfrey',\n",
       " 'Elif',\n",
       " 'LY',\n",
       " 'Fat Pat',\n",
       " 'teerapat chada',\n",
       " 'Ginevra Ranieri',\n",
       " 'Gabriela Carrilho',\n",
       " 'Carol Cates',\n",
       " 'Angus Kwok',\n",
       " 'Inass Khan',\n",
       " 'student123',\n",
       " 'XINGMING',\n",
       " 'Lisa',\n",
       " 'Helen Chan',\n",
       " 'Sophie Zubyk',\n",
       " 'Albert',\n",
       " 'Sooraj Muhammed',\n",
       " 'Caitrona Nic Uidhir',\n",
       " 'Naqibah Osman',\n",
       " nan,\n",
       " 'Eugene_Fitz',\n",
       " 'Wan Teng',\n",
       " 'April',\n",
       " 'Shireen Ong',\n",
       " 'Georgina Stephanou',\n",
       " 'Anna Georgiou',\n",
       " 'Lim Ee Ee',\n",
       " 'Victoria Moyo',\n",
       " 'Crystal Koo',\n",
       " 'Yuan Xu',\n",
       " 'Nicole Olmos',\n",
       " 'Li Zhonghao',\n",
       " 'Kaisa Rautiainen',\n",
       " 'Laura',\n",
       " 'Selis Tutkum',\n",
       " 'B',\n",
       " 'Tess Robinson',\n",
       " 'Leah0',\n",
       " 'Kristie',\n",
       " 'Elvis Wang',\n",
       " 'Jane',\n",
       " 'J',\n",
       " 'Maria',\n",
       " 'Thelma H.',\n",
       " 'erika']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(authors[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('aditya')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = str(authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['Rob', 'Sabine L', 'Imran Alvi', 'Jonatan Karlsson', 'Ewa', 'ekin rnek', 'Martina Nedkova', 'aseel sultan', 'Sylvie', 'Alexandra Badut', 'Lawsuit', 'Linus', 'Marilyn Ohemaa', 'Rafeeda Abedin', 'Maria Vittoria', 'AP', 'Nathalie Clark', 'Clau Ramos', 'Laura Biezup', 'Scarlett,', 'Tabitha Mullock', 'Christopher Onderstall', 'Ann-Michelle Mull', 'Alex G', 'Julia', 'Shen May Khoo', 'Joana', 'jorge kronfle', 'Zaya G', 'Claudia Hon', 'Jonty', 'Claudia Hon', 'Julie', '\\\\xa0Hyunhoi', 'Afsana Mahtani', 'Antonella', '\\\\xa0Hyunhoi,', 'Manu Moreau', 'Khalad Al-Muhaysh', 'Selina Abdul Kareem', 'Srika N.', 'Fanni Szabo', 'Aiwen Chua', 'Katrina So', 'Sang Hun Kim', 'Rena Abidova', 'G O-I', 'Kittipit Viseshsin', 'Iustina Chirila', 'Yara Ha', 'Raluca Baicu', 'Burcu', 'Yana', 'Yana Pencheva', 'Srika N.', 'Jess', 'Michal', 'Max Hombach', 'Luca', 'Saksham', 'Penghui Shi', 'Panagiotis Gr', 'Joanna Rie', 'Odette Duerden', 'anda oglakci', 'Rhiannon', ' ', 'Natasha', 'Patricia Eliana Gheorghe', 'Julita Stefaniak', 'Ian Wong', 'JSJ GANG', 'Musomum', 'Baldpenguin', 'Wink', 'Matthew', 'Petra Dietz', 'Trisyia', 'ediblesweater', 'Diane', 'Mary Ana', 'Jon', 'Chloe', 'Broke uni stduent', 'Sebastiano Pignato', 'Jehquisha', 'Keana', 'Liv', 'mike', 'mike', 'NL', 'Yagmur', 'Sam', 'Saharat Anuwatmatee', 'Hayley', 'Victoria Recean', 'kp', 'James', 'Fay', 'Nneoma', 'Mizza', 'Karen', 'c mason', 'Aisha', 'Arnau', 'Flo', 'Rachael', 'Tebogo Bembe', 'Yitong Wang', 'Rebecca', 'Anonymous', 'wong hoikwan', 'Vladimir Sagalevich', 'Konstantina Sotiriou', 'Kay Wong', 'tejiri ishaka', 'Mizza', '', 'Mir', 'Victoria E Nwokolo', 'Marta', 'Jade Johnson', 'Ariel Chen', 'MB', 'Yasmine Aminanda', 'Daniel Ooi', 'Lenita LuxV', 'Zen Dhammatorn', 'Mizza', 'Samuel Mensah', 'leigh', 'Xin Di Kwong', 'Daniela Simes', 'Ariane Strike', '*', 'Sophia C', 'Rahil Gandhi', 'Charlotte Bowerman', 'agnes roze', 'Rahil Gandhi', 'Yuou Zhao', 'Charlotte', 'daniel', 'yasmin timol', 'Will Marchant', 'Maggie Talty-Sanghera', 'Constanza Mondragon', 'S Kelly', 'Ronin', 'Becky Says', 'ANASTASIA', 'Damien Gal', 'Oliver', 'MD', 'Wei Vern Kok', 'Sherice', 'Charles', 'Frank Li', 'Tamara Garcia Pereira', 'Godfrey', 'Elif', 'LY', 'Fat Pat', 'teerapat chada', 'Ginevra Ranieri', 'Gabriela Carrilho', 'Carol Cates', 'Angus Kwok', 'Inass Khan', 'student123', 'XINGMING', 'Lisa', 'Helen Chan', 'Sophie Zubyk', 'Albert', 'Sooraj Muhammed', 'Caitrona Nic Uidhir', 'Naqibah Osman', nan, 'Eugene_Fitz', 'Wan Teng', 'April', 'Shireen Ong', 'Georgina Stephanou', 'Anna Georgiou', 'Lim Ee Ee', 'Victoria Moyo', 'Crystal Koo', 'Yuan Xu', 'Nicole Olmos', 'Li Zhonghao', 'Kaisa Rautiainen', 'Laura', 'Selis Tutkum', 'B', 'Tess Robinson', 'Leah0', 'Kristie', 'Elvis Wang', 'Jane', 'J', 'Maria', 'Thelma H.', 'erika']\""
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-e3c855bf0270>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#abbre = []\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m204\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mauthors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauthors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "#abbre = []\n",
    "for i in range(0,204):\n",
    "    authors[i] = str(authors[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#abbres = []\n",
    "for i in range(0,204):\n",
    "    if authors[i] == \"\":\n",
    "        print(authors[i])\n",
    "        ab.append(authors[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in abbre:\n",
    "    abbres.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abrrevations = pd.DataFrame(abbres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = abrrevations[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbre1.append(abbre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbre1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "mytext = \"ML how are YU\"\n",
    "mytext = re.findall(r\"\\b[A-Z]{2,}\\b\", \"\", mytext)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = []\n",
    "for i in authors:\n",
    "    a = i.split()\n",
    "    fn.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = []\n",
    "for i in authors:\n",
    "   \n",
    "    a = i.split()\n",
    "    m.append(a[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#abv2 = []\n",
    "for name in m:\n",
    "    if len(name)==2:\n",
    "        abv2.append(name)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abv2.append(ab[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ab2:\n",
    "    ab1.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbrevations = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbrevations['Abbrevation'] = ab1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbrevations = abbrevations.drop('Abbrevation', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbrevations.to_csv('Abbre.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABV = pd.DataFrame(abv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABV.to_csv('ABV.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = pd.read_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = dc[dc['body'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp1 = dp[dp['rating']!=5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Female\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Female\n"
     ]
    }
   ],
   "source": [
    "li1 = dp1['title']\n",
    "li2 = []\n",
    "for i in li1:\n",
    "    li2.append(genderpredictor1(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(li1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = ['Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Female',\n",
    "'Female',\n",
    "'Male',\n",
    "'Female',\n",
    "'Female',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Female',\n",
    "'Female',\n",
    "'Male',\n",
    "'Female',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Female',\n",
    "'Female',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Female',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Female',\n",
    "'Female',\n",
    "'Female',\n",
    "'Female',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Female',\n",
    "'Male',\n",
    "'Female',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Francesca Carioti\n",
       "1            Helen Zhang\n",
       "2             Mark Aduol\n",
       "3       Ola Sidorkiewicz\n",
       "4        Farrel Adhitama\n",
       "             ...        \n",
       "276                  \n",
       "277       deok young lee\n",
       "278              Siyu Su\n",
       "279           Lokyi Tsoi\n",
       "280       mulugeta yimer\n",
       "Name: title, Length: 281, dtype: object"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-118-f3d82464a8ae>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dp1['gender'] = gen\n"
     ]
    }
   ],
   "source": [
    "dp1['gender'] = gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp1 = dp1[dp1['rating'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp1 = dp1[dp1['rating']!=4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp1.to_csv('google data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Female\n",
      "Female\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Male\n",
      "Female\n",
      "Male\n"
     ]
    }
   ],
   "source": [
    "list9 = dp['title']\n",
    "list10 = []\n",
    "for i in list9:\n",
    "    list10.append(genderpredictor1(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "list11 = ['Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Female',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Female',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Female',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Female',\n",
    "'Female',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Female',\n",
    "'Female',\n",
    "'Female',\n",
    "'Female',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Female',\n",
    "'Female',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Female',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Female',\n",
    "'Female',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Female',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Female',\n",
    "'Female',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Female',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Female',\n",
    "'Female',\n",
    "'Female',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male',\n",
    "'Female',\n",
    "'Male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-109-2ac8e7aaec7a>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dp['gender'] = list11\n"
     ]
    }
   ],
   "source": [
    "dp['gender'] = list11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.to_csv('lov2_o.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
